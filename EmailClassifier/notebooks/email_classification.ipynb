{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9d6451-4e88-4c52-ac09-78bdf69c9c07",
   "metadata": {},
   "source": [
    "# === Needed imports ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da4e2e5-74e9-4ab2-b211-f1f62b1c25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Heatmap\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "df = pd.read_csv('../data/Phishing_Legitimate_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16c0a0-60bc-4590-9ae9-ce605ffa3b7a",
   "metadata": {},
   "source": [
    "# === Analyzing the dataset ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a1953-d2af-4565-ac9d-a763cef34502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 entries in the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36a71f-58f7-42ff-9ab2-d09f14e6f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of all columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48247b11-1924-47d5-b965-8bfa2dbc6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Values\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f6ea97-3853-43e6-b316-1ceb26eeddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-column = classification (phishing / no phishing)\n",
    "df.rename(columns={'CLASS_LABEL': 'labels'}, inplace=True)\n",
    "\n",
    "# Check Count of \"Phishing-Entries\" and \"Non-Phishing-Entries\" in the dataframe\n",
    "df['labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09985231-c09b-4299-a741-c6be9e5cf76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are null-values in the data\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4013b-5b44-442f-a0a4-9863111358e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column \"id\" is not important for training a model\n",
    "df = df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1845ea-20a9-447d-bd7b-7b168b667ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot outliners in \"UrlLength\"\n",
    "df['UrlLength'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a60bdc-5b55-41e0-80cf-7478f0e2f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['UrlLength'].quantile(0.25)\n",
    "Q3 = df['UrlLength'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f\"IQR: {IQR}\")\n",
    "\n",
    "# Outliners = +/- 1.5 * IQR\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['UrlLength'] < lower_bound) | (df['UrlLength'] > upper_bound)]\n",
    "print(f\"Count of Outliners (UrlLength): {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5a6b22-66a7-4034-a4bc-164fca35be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot outliners in \"NumDots\"\n",
    "df['NumDots'].plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765695de-ebef-4d82-b6e2-68f63b2a99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df['NumDots'].quantile(0.25)\n",
    "Q3 = df['NumDots'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f\"IQR: {IQR}\")\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df['NumDots'] < lower_bound) | (df['NumDots'] > upper_bound)]\n",
    "print(f\"Count of Outliners (NumDots): {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4f39c-e07e-4424-bc5e-c7799565bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation and sort in descending order\n",
    "correlation = df.corr()['labels'].drop('labels').sort_values(ascending=False)\n",
    "\n",
    "# Plotting\n",
    "\n",
    "# Set figure size for better readability\n",
    "plt.figure(figsize=(8, 15))\n",
    "\n",
    "# Create heatmap with sorted correlations\n",
    "sns.heatmap(correlation.to_frame(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=1, cbar=False)\n",
    "\n",
    "plt.title(\"Correlation of Features with 'labels'\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c78116-780e-4167-9531-aa96e87cd3ec",
   "metadata": {},
   "source": [
    "## == Analysis of Empty Column: \"HttpsInHostname\" =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016bc909-5438-4709-9314-91a23662538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values\n",
    "print(df['HttpsInHostname'].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0819ec6-f331-495d-b90b-bae9e1aedf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HttpInHostname will be dropped because the correlation cannot be calculated\n",
    "df = df.drop(columns=['HttpsInHostname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00815599-8c96-4871-99dc-c786d77f0a77",
   "metadata": {},
   "source": [
    "# === RandomForest for Calculation of importance of the features ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801769f-5e8e-4416-8bd0-3fc637b07aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['labels'])\n",
    "y = df['labels']\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model.fit(X, y)\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance.plot(kind='bar', color='steelblue')\n",
    "plt.title(\"Feature Importance from Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8064fa1d-f3ff-49c1-8a5d-797a56d41ba4",
   "metadata": {},
   "source": [
    "# === RandomForest with reduced amount of features ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe69c7-d616-4292-8cf1-8dc3ef7f9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 most important features\n",
    "top_features = feature_importance[:15].index  \n",
    "\n",
    "X_reduced = df[top_features]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=77)\n",
    "\n",
    "model_reduced = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_reduced.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_reduced.predict(X_test)\n",
    "\n",
    "feature_importance = pd.Series(model_reduced.feature_importances_, index=X_reduced.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance.plot(kind='bar', color='steelblue')\n",
    "plt.title(\"Feature Importance for reduced features from Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c32415-88dc-4e79-a0ef-8e7af1de1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation with 5 folds\n",
    "\n",
    "scores = cross_val_score(model_reduced, X_reduced, y, cv=5)\n",
    "\n",
    "print(f\"Cross-Validation Accuracy: {np.mean(scores):.2f} ± {np.std(scores):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a11675-00b8-4b4a-a953-69f9bf090409",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df[top_features].corr(), cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Correlation between Features\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701b0adc-26b9-4840-8442-cb3101411314",
   "metadata": {},
   "source": [
    "### == Check correlation for the 15 most important features =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01eee6d-6af6-410a-8878-63803ec9eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_reduced.corrwith(y).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c73e92-fc43-4889-bbe2-6f802a1f61bd",
   "metadata": {},
   "source": [
    "# === XGBoost with Top-Features ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bff747-5284-4870-9384-3e99994022da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=77)\n",
    "\n",
    "model_xgb = XGBClassifier(n_estimators=500, learning_rate=0.05, max_depth=6, subsample=0.8, colsample_bytree=0.8, eval_metric='logloss')\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93c22f-fc51-4b53-ac22-f45ad37e57ee",
   "metadata": {},
   "source": [
    "# === Reserve 5% of the original data for testing ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81259c9-aa05-4d6b-b24e-481dd635e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare full feature matrix and labels\n",
    "X_full_all = df.drop(\"labels\", axis=1)\n",
    "y_full_all = df[\"labels\"]\n",
    "\n",
    "# 95% train, 5% test (stratified)\n",
    "X_train_full, X_eval_full, y_train_full, y_eval_full = train_test_split(\n",
    "    X_full_all, y_full_all, test_size=0.05, random_state=77, stratify=y_full_all\n",
    ")\n",
    "\n",
    "# Train full-feature model on 95% of data\n",
    "model_full_split = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_full_split.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Feature importances from model_full_split\n",
    "importances_split = pd.Series(model_full_split.feature_importances_, index=X_train_full.columns)\n",
    "top_features_split = importances_split.sort_values(ascending=False)[:15].index\n",
    "\n",
    "# Reduce datasets to top features\n",
    "X_train_reduced = X_train_full[top_features_split]\n",
    "X_eval_reduced = X_eval_full[top_features_split]\n",
    "\n",
    "# Train reduced model\n",
    "model_reduced_split = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_reduced_split.fit(X_train_reduced, y_train_full)\n",
    "\n",
    "# Predictions\n",
    "y_pred_full_split = model_full_split.predict(X_eval_full)\n",
    "y_pred_reduced_split = model_reduced_split.predict(X_eval_reduced)\n",
    "\n",
    "# Evaluation: Full-feature model\n",
    "print(\"Evaluation (Full Feature Model, 5% test split)\")\n",
    "print(classification_report(y_eval_full, y_pred_full_split))\n",
    "print(confusion_matrix(y_eval_full, y_pred_full_split))\n",
    "\n",
    "# Evaluation: Top-feature model\n",
    "print(\"\\nEvaluation (Top Feature Model, 5% test split)\")\n",
    "print(classification_report(y_eval_full, y_pred_reduced_split))\n",
    "print(confusion_matrix(y_eval_full, y_pred_reduced_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f627091-c365-421e-a166-a8f932f8f390",
   "metadata": {},
   "source": [
    "# === Test the model (all features) with generated data (10 rows) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e9955-405f-4349-8584-b9f227ec0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let ChatGPT generate 10 rows similar to the original data\n",
    "df_testset = pd.read_csv(\"../data/phishing_mini_testset_ten-rows.csv\")\n",
    "\n",
    "X_test = df_testset.drop(columns=[\"CLASS_LABEL\", \"HttpsInHostname\"])\n",
    "y_test = df_testset[\"CLASS_LABEL\"]\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nMisclassifications\")\n",
    "df_errors = df_testset[y_pred != y_test]\n",
    "display(df_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d84dcf-860f-4073-8f7e-85105f3c61a1",
   "metadata": {},
   "source": [
    "# === Test the model with generated data (100 rows) - but many duplicates ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c420ba-c20b-445e-aba8-0a967d40f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testset_100_rows_with_duplicates = pd.read_csv(\"../data/phishing_testset_hundred-rows.csv\")\n",
    "\n",
    "X_test_full = df_testset_100_rows_with_duplicates.drop(columns=[\"CLASS_LABEL\", \"HttpsInHostname\"])\n",
    "X_test_top = X_test_full[top_features]\n",
    "y_test = df_testset_100_rows_with_duplicates[\"CLASS_LABEL\"]\n",
    "\n",
    "y_pred_full = model.predict(X_test_full)\n",
    "y_pred_top = model_reduced.predict(X_test_top)\n",
    "\n",
    "print(classification_report(y_test, y_pred_full))\n",
    "print(confusion_matrix(y_test, y_pred_full))\n",
    "print(classification_report(y_test, y_pred_top))\n",
    "print(confusion_matrix(y_test, y_pred_top))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297a7b7d-92cb-460e-97d8-3aeb4c5bb602",
   "metadata": {},
   "source": [
    "### == Test the model with generated data (100 rows) - but many duplicates V2 =="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7641f-38e7-417e-94e5-5b73f45d62e1",
   "metadata": {},
   "source": [
    "Although the models used (model & model_reduced) have not been modified, a 0% phishing detection raises suspicions.\n",
    "\n",
    "For this reason, two new models have been trained for this specific case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be6b88-b7b9-445e-97ee-51f33f9ca3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the new X from the full csv\n",
    "X_full_100 = df.drop(columns=[\"labels\"])\n",
    "y_full_100 = df[\"labels\"]\n",
    "\n",
    "# Retrieve the new X but only with the 15 top features\n",
    "X_top_100 = df[top_features]\n",
    "\n",
    "# Train full modell again\n",
    "model_full_100 = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_full_100.fit(X_full_100, y_full_100)\n",
    "\n",
    "# Train reduced-feature model again\n",
    "model_top_100 = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_top_100.fit(X_top_100, y_full_100)\n",
    "\n",
    "# Load generated test set (with duplicates)\n",
    "\n",
    "df_testset_100_faulty = pd.read_csv(\"../data/phishing_testset_hundred-rows.csv\")\n",
    "\n",
    "X_test_full = df_testset_100_faulty.drop(columns=[\"CLASS_LABEL\", \"HttpsInHostname\"])\n",
    "X_test_top = X_test_full[top_features]\n",
    "y_test = df_testset_100_faulty[\"CLASS_LABEL\"]\n",
    "\n",
    "# Evaluate full-feature model\n",
    "y_pred_full = model_full_100.predict(X_test_full)\n",
    "\n",
    "print(\"Evaluation: Full-Feature Model\")\n",
    "print(classification_report(y_test, y_pred_full))\n",
    "print(confusion_matrix(y_test, y_pred_full))\n",
    "\n",
    "# Evaluate top-feature model\n",
    "y_pred_top = model_top_100.predict(X_test_top)\n",
    "\n",
    "print(\"\\nEvaluation: Top-Feature Model\")\n",
    "print(classification_report(y_test, y_pred_top))\n",
    "print(confusion_matrix(y_test, y_pred_top))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0d474-776d-4400-8afe-33f1bce2015c",
   "metadata": {},
   "source": [
    "These results indicate that the reduced model fails to identify generated phishing samples in this dataset, likely due to insufficient representation of relevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4e6a52-3648-4d6d-a89b-106ab14d34d9",
   "metadata": {},
   "source": [
    "# === Test the model with generated data (100 rows) - unique rows ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff074c9-6a10-4cf8-b82f-b5f91db32563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT generated 100 unique rows similar to the original data\n",
    "df_testset_100_unique = pd.read_csv(\"../data/phishing_testset_100_unique.csv\")\n",
    "\n",
    "# Input features and labels\n",
    "X_test_full = df_testset_100_unique.drop(columns=[\"CLASS_LABEL\", \"HttpsInHostname\"])\n",
    "y_test = df_testset_100_unique[\"CLASS_LABEL\"]\n",
    "\n",
    "# Prepare reduced feature input\n",
    "X_test_top = X_test_full[top_features]\n",
    "\n",
    "# Predictions\n",
    "y_pred_full = model.predict(X_test_full)\n",
    "y_pred_top = model_reduced.predict(X_test_top)\n",
    "\n",
    "# Full-feature model evaluation\n",
    "print(\"Evaluation: Full-Feature Model\")\n",
    "print(classification_report(y_test, y_pred_full))\n",
    "print(confusion_matrix(y_test, y_pred_full))\n",
    "\n",
    "# Top-feature model evaluation\n",
    "print(\"\\nEvaluation: Top-Feature Model\")\n",
    "print(classification_report(y_test, y_pred_top))\n",
    "print(confusion_matrix(y_test, y_pred_top))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a455af-3492-4522-9228-7c67d3f9ee01",
   "metadata": {},
   "source": [
    "### == Test the model with generated data (100 rows) - unique rows V2 =="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea35d69-d794-4b60-b0dd-4b8f5628ba3d",
   "metadata": {},
   "source": [
    "Again, two new models were trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e37c05-27af-4bb2-b0bd-2fb9626d92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train new models for the unique 100-row test set\n",
    "\n",
    "X_full_unique = df.drop(columns=[\"labels\"])\n",
    "y_full_unique = df[\"labels\"]\n",
    "\n",
    "X_top_unique = df[top_features]\n",
    "\n",
    "# Train full-feature model again\n",
    "model_full_unique = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_full_unique.fit(X_full_unique, y_full_unique)\n",
    "\n",
    "# Train top-feature model again\n",
    "model_top_unique = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_top_unique.fit(X_top_unique, y_full_unique)\n",
    "\n",
    "# Load generated test set (100 unique rows)\n",
    "\n",
    "df_testset_100_unique = pd.read_csv(\"../data/phishing_testset_100_unique.csv\")\n",
    "\n",
    "X_test_full = df_testset_100_unique.drop(columns=[\"CLASS_LABEL\", \"HttpsInHostname\"])\n",
    "X_test_top = X_test_full[top_features]\n",
    "y_test = df_testset_100_unique[\"CLASS_LABEL\"]\n",
    "\n",
    "# Evaluate full-feature model\n",
    "y_pred_full = model_full_unique.predict(X_test_full)\n",
    "\n",
    "print(\"Evaluation: Full-Feature Model\")\n",
    "print(classification_report(y_test, y_pred_full))\n",
    "print(confusion_matrix(y_test, y_pred_full))\n",
    "\n",
    "# Evaluate top-feature model\n",
    "y_pred_top = model_top_unique.predict(X_test_top)\n",
    "\n",
    "print(\"\\nEvaluation: Top-Feature Model\")\n",
    "print(classification_report(y_test, y_pred_top))\n",
    "print(confusion_matrix(y_test, y_pred_top))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030fdd5-09d5-4f9a-8041-930dc8713a0e",
   "metadata": {},
   "source": [
    "# === Reading E-Mails from .eml-Files ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd16a7-d368-4723-ab22-41fb63f6afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Clamp a value between a minimum and a maximum (used to normalize feature values)\n",
    "def clamp(value, min_val, max_val):\n",
    "    return max(min(value, max_val), min_val)\n",
    "\n",
    "# Extract technical URL-based features from url-list\n",
    "def extract_url_features(urls):\n",
    "    features = {\n",
    "        \"NumDots\": 0, \"SubdomainLevel\": 0, \"PathLevel\": 0, \"UrlLength\": 0,\n",
    "        \"NumDash\": 0, \"NumDashInHostname\": 0, \"AtSymbol\": 0, \"TildeSymbol\": 0,\n",
    "        \"NumUnderscore\": 0, \"NumPercent\": 0, \"NumQueryComponents\": 0,\n",
    "        \"NumAmpersand\": 0, \"NumHash\": 0, \"NumNumericChars\": 0, \"NoHttps\": 0,\n",
    "        \"RandomString\": 0, \"IpAddress\": 0, \"HttpsInHostname\": 0,\n",
    "        \"HostnameLength\": 0, \"PathLength\": 0, \"QueryLength\": 0,\n",
    "        \"DoubleSlashInPath\": 0,\n",
    "    }\n",
    "\n",
    "    for url in urls:\n",
    "        parsed = urlparse(url)\n",
    "        hostname = parsed.hostname or \"\"\n",
    "        path = parsed.path or \"\"\n",
    "        query = parsed.query or \"\"\n",
    "\n",
    "        # Counts how often '//' appears inside the path (hidden redirects?)\n",
    "        features[\"DoubleSlashInPath\"] += path.count(\"//\")\n",
    "\n",
    "        # 0 / 1 if the hostname itself contains the string \"https\"\n",
    "        features[\"HttpsInHostname\"] += int(\"https\" in hostname)\n",
    "\n",
    "        # 0 / 1 if the hostname is an IP address instead of domain name\n",
    "        features[\"IpAddress\"] += int(bool(re.match(r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", hostname)))\n",
    "    \n",
    "        # Number of key=value components in the query string (e.g., ?a=1&b=2 -> 2 components)\n",
    "        features[\"NumQueryComponents\"] += len(query.split(\"&\")) if query else 0\n",
    "    \n",
    "        # 0 / 1 if any path segment is unusually long and lacks vowels (often machine-generated)\n",
    "        features[\"RandomString\"] += int(any(\n",
    "            len(part) > 10 and not re.search(r'[aeiou]', part)\n",
    "            for part in path.split(\"/\")\n",
    "        ))\n",
    "    \n",
    "        # Number of dots in the hostname, minus one to exclude the top-level domain\n",
    "        features[\"SubdomainLevel\"] += max(0, hostname.count(\".\") - 1)       \n",
    "        \n",
    "        features[\"AtSymbol\"] += url.count(\"@\")\n",
    "        features[\"HostnameLength\"] += len(hostname) if hostname else 0\n",
    "        features[\"NoHttps\"] += int(not url.startswith(\"https\"))\n",
    "        features[\"NumAmpersand\"] += url.count(\"&\")\n",
    "        features[\"NumDash\"] += url.count(\"-\")\n",
    "        features[\"NumDashInHostname\"] += hostname.count(\"-\")\n",
    "        features[\"NumDots\"] += url.count(\".\")\n",
    "        features[\"NumHash\"] += url.count(\"#\")\n",
    "        features[\"NumNumericChars\"] += sum(c.isdigit() for c in url)\n",
    "        features[\"NumPercent\"] += url.count(\"%\")\n",
    "        features[\"NumUnderscore\"] += url.count(\"_\")\n",
    "        features[\"PathLength\"] += len(path)\n",
    "        features[\"PathLevel\"] += path.count(\"/\")\n",
    "        features[\"QueryLength\"] += len(query)\n",
    "        features[\"TildeSymbol\"] += url.count(\"~\")\n",
    "        features[\"UrlLength\"] += len(url)\n",
    "\n",
    "    # Clamp selected numeric features to keep them within expected ranges\n",
    "    features[\"HostnameLength\"] = clamp(features[\"HostnameLength\"], 4, 137)\n",
    "    features[\"PathLength\"] = clamp(features[\"PathLength\"], 0, 161)\n",
    "    features[\"QueryLength\"] = clamp(features[\"QueryLength\"], 0, 188)\n",
    "    features[\"UrlLength\"] = clamp(features[\"UrlLength\"], 12, 253)\n",
    "    features[\"SubdomainLevel\"] = clamp(features[\"SubdomainLevel\"], 0, 14)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Calculate the ratio of external hyperlinks and resources in the email body\n",
    "def calculate_external_link_ratios(body: str, sender: str):\n",
    "    snd_domain = sender.split(\"@\")[-1].lower() if sender and \"@\" in sender else \"\"\n",
    "\n",
    "    urls = re.findall(r'https?://[^\\s\"<>()]+', body)\n",
    "\n",
    "    # Resource-URLs (src= / href=)\n",
    "    resource_urls = re.findall(r'(?:src|href)=[\"\\'](https?://[^\"\\']+)[\"\\']', body.lower())\n",
    "\n",
    "    # A link is considered external if its domain differs from the senders domain\n",
    "    def is_external(url, ref_domain):\n",
    "        parsed = urlparse(url)\n",
    "        hostname = parsed.hostname or \"\"\n",
    "        return ref_domain not in hostname.lower()\n",
    "\n",
    "    num_ext_links = sum(is_external(u, snd_domain) for u in urls)\n",
    "    pct_ext_links = (num_ext_links / len(urls)) if urls else 0\n",
    "\n",
    "    num_ext_resources = sum(is_external(u, snd_domain) for u in resource_urls)\n",
    "    pct_ext_resources = (num_ext_resources / len(resource_urls)) if resource_urls else 0\n",
    "\n",
    "    return pct_ext_links, pct_ext_resources\n",
    "\n",
    "def domain_from_email(email_address):\n",
    "    if not email_address or \"@\" not in email_address:\n",
    "        return \"\"\n",
    "    return email_address.split(\"@\")[-1].lower()\n",
    "\n",
    "# Get the main domain (second-level + top-level) from a full hostname\n",
    "def get_main_domain(hostname):\n",
    "    parts = hostname.split(\".\")\n",
    "    return \".\".join(parts[-2:]) if len(parts) >= 2 else hostname\n",
    "\n",
    "# Extracts large set of phishing-related features\n",
    "def extract_features_from_eml(subject, sender, recipient, body, filename=\"\"):\n",
    "    features = {}\n",
    "\n",
    "    urls = re.findall(r'https?://[^\\s\"<>()]+', body)\n",
    "\n",
    "    known_brands = [\n",
    "        \"paypal\", \"apple\", \"amazon\", \"sparkasse\", \"dhl\", \"deutschebank\",\n",
    "        \"commerzbank\", \"ebay\", \"netflix\", \"microsoft\", \"google\", \"instagram\",\n",
    "        \"facebook\", \"linkedin\", \"postbank\", \"visa\", \"mastercard\", \"americanexpress\",\n",
    "        \"fedex\", \"ups\", \"klarna\", \"telekom\", \"vodafone\", \"o2\", \"spotify\", \"airbnb\"\n",
    "    ]\n",
    "    \n",
    "    sensitive_words = [\n",
    "        \"account\", \"verify\", \"secure\", \"login\", \"update\", \"confirm\",\n",
    "        \"password\", \"click\", \"access\", \"billing\", \"bank\", \"credit\", \"ssn\",\n",
    "        \"social\", \"security\", \"alert\", \"unusual\", \"attempt\", \"fraud\",\n",
    "        \"locked\", \"expired\", \"immediately\", \"urgent\", \"attention\",\n",
    "        \"suspend\", \"important\", \"reset\", \"re-enter\",\n",
    "    \n",
    "        \"konto\", \"verifizieren\", \"sicher\", \"einloggen\", \"anmelden\",\n",
    "        \"passwort\", \"aktualisieren\", \"bestätigen\", \"zahlung\", \"abrechnung\",\n",
    "        \"kreditkarte\", \"sofort\", \"dringend\", \"wichtig\", \"gesperrt\",\n",
    "        \"abgelaufen\", \"zugang\", \"identität\", \"prüfung\", \"eingabe\",\n",
    "        \"sicherheitsüberprüfung\", \"reaktivieren\", \"informationen\", \"bank\",\n",
    "        \"onlinebanking\", \"pin\", \"tan\", \"sicherheitscode\", \"freischalten\"\n",
    "    ]\n",
    "\n",
    "    # Aggregate technical URL-based features across all URLs in the body\n",
    "    url_features = extract_url_features(urls)\n",
    "    features.update(url_features)\n",
    "\n",
    "    parsed = urlparse(urls[0]) if urls else None\n",
    "    hostname = parsed.hostname if parsed else \"\"\n",
    "    path = parsed.path if parsed else \"\"\n",
    "    query = parsed.query if parsed else \"\"\n",
    "    \n",
    "    # Extract local part of the recipient (e.g., \"john\" from john@example.com)\n",
    "    recipient_local = recipient.split(\"@\")[0] if recipient and \"@\" in recipient else \"\"   \n",
    "\n",
    "    # Count occurrences of sensitive keywords (case-insensitive)\n",
    "    features[\"NumSensitiveWords\"] = sum(\n",
    "        bool(re.search(rf'\\b{re.escape(word)}\\b', body, flags=re.IGNORECASE))\n",
    "        for word in sensitive_words\n",
    "    )\n",
    "\n",
    "    # Compare sender domain with the domain of the first link\n",
    "    sender_domain = domain_from_email(sender)\n",
    "    link_domain = get_main_domain(hostname)    \n",
    "    features[\"FrequentDomainNameMismatch\"] = int(sender_domain != link_domain) if sender_domain and link_domain else 0\n",
    "\n",
    "    # Calculate percentage of external links and resources\n",
    "    pct_ext_links, pct_ext_resources = calculate_external_link_ratios(body, sender)\n",
    "    features[\"PctExtHyperlinks\"] = clamp(pct_ext_links, 0, 1)\n",
    "    features[\"PctExtResourceUrls\"] = clamp(pct_ext_resources, 0, 1)\n",
    "\n",
    "    # Check if form actions post to external domains (not sender's)\n",
    "    form_actions = re.findall(r'action=[\"\\'](https?://[^\"\\']+)[\"\\']', body.lower())\n",
    "    features[\"AbnormalFormAction\"] = int(any(\n",
    "        urlparse(url).hostname and sender_domain not in urlparse(url).hostname.lower()\n",
    "        for url in form_actions\n",
    "    ))\n",
    "    \n",
    "    features[\"DomainInSubdomains\"] = int(recipient_local in \".\".join(hostname.split(\".\")[:-2])) if hostname else 0\n",
    "    features[\"DomainInPaths\"] = int(recipient_local in path)\n",
    "    features[\"EmbeddedBrandName\"] = int(any(b in body.lower() for b in known_brands))\n",
    "\n",
    "    # Technical \"tricks\"\n",
    "    features[\"ExtFavicon\"] = int(\"favicon\" in body.lower() and \"http\" in body.lower())\n",
    "    features[\"InsecureForms\"] = int(\"<form\" in body.lower() and \"http:\" in body.lower())\n",
    "    features[\"RelativeFormAction\"] = int('action=\"/' in body.lower())\n",
    "    features[\"ExtFormAction\"] = int('action=\"http' in body.lower())\n",
    "    features[\"PctNullSelfRedirectHyperlinks\"] = clamp(int('href=\"#\"' in body.lower()) / len(urls) if urls else 0, 0, 1)\n",
    "\n",
    "    # Client-side deception techniques\n",
    "    features[\"FakeLinkInStatusBar\"] = int(\"onmouseover\" in body.lower() and \"status\" in body.lower())\n",
    "    features[\"RightClickDisabled\"] = int(\"event.button==2\" in body.lower())\n",
    "    features[\"PopUpWindow\"] = int(\"window.open\" in body.lower())\n",
    "    features[\"SubmitInfoToEmail\"] = int(\"mailto:\" in body.lower())\n",
    "\n",
    "    # HTML structure anomalies\n",
    "    features[\"IframeOrFrame\"] = int(\"<iframe\" in body.lower() or \"<frame\" in body.lower())\n",
    "    features[\"MissingTitle\"] = int(\"<title\" not in body.lower())\n",
    "    features[\"ImagesOnlyInForm\"] = int(\"<form\" in body.lower() and \"<img\" in body.lower())\n",
    "\n",
    "    # Redundant (clamped or grouped) features – required by model\n",
    "    features[\"SubdomainLevelRT\"] = features[\"SubdomainLevel\"]\n",
    "    features[\"UrlLengthRT\"] = features[\"UrlLength\"]\n",
    "    features[\"PctExtResourceUrlsRT\"] = features[\"PctExtResourceUrls\"]\n",
    "    features[\"AbnormalExtFormActionR\"] = features[\"AbnormalFormAction\"]\n",
    "    features[\"PctExtNullSelfRedirectHyperlinksRT\"] = features[\"PctNullSelfRedirectHyperlinks\"]\n",
    "    features[\"ExtMetaScriptLinkRT\"] = int(\"<script\" in body.lower() or \"<meta\" in body.lower() or \"<link\" in body.lower())\n",
    "\n",
    "    # Assign label from filename if known (phish/legit), else mark unknown\n",
    "    if \"phish\" in filename.lower():\n",
    "        features[\"CLASS_LABEL\"] = 1\n",
    "    elif \"legit\" in filename.lower():\n",
    "        features[\"CLASS_LABEL\"] = 0\n",
    "    else:\n",
    "        features[\"CLASS_LABEL\"] = \"unknown\"\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9143bd3-1d65-474a-84d8-3a9805eedc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "def process_eml_folder(folder_path):\n",
    "    all_features = []\n",
    "\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".eml\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "\n",
    "            with open(file_path, 'rb') as f:\n",
    "                msg = BytesParser(policy=policy.default).parse(f)\n",
    "\n",
    "            subject = msg['subject']\n",
    "            sender = msg['from']\n",
    "            recipient = msg['to']\n",
    "\n",
    "            body = \"\"\n",
    "\n",
    "            if msg.is_multipart():\n",
    "                for part in msg.walk():\n",
    "                    if part.get_content_type() == \"text/html\":\n",
    "                        body = part.get_content()\n",
    "                        break\n",
    "                    elif part.get_content_type() == \"text/plain\":\n",
    "                        body = part.get_content()\n",
    "            else:\n",
    "                body = msg.get_content()\n",
    "\n",
    "            filename = os.path.basename(file_path)\n",
    "\n",
    "            features = extract_features_from_eml(subject, sender, recipient, body, filename=filename)\n",
    "            features[\"FILENAME\"] = file\n",
    "\n",
    "            all_features.append(features)\n",
    "\n",
    "    df = pd.DataFrame(all_features)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1b6b9e-ba68-4369-8b04-ff7eb3808ef9",
   "metadata": {},
   "source": [
    "# === Full output and information of eml-Data ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d51511f-01ca-4500-9568-a35ec271ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"../data/mails/real_mails_train\"\n",
    "df_eml = process_eml_folder(folder_path)\n",
    "\n",
    "df_eml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a225d9-7f13-4bb2-a243-466745d4ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the columns if everything is still correct\n",
    "\n",
    "print(df.columns)\n",
    "print(f\"\\nCount of features: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276254a-02b2-4fa5-a584-5627d002a91c",
   "metadata": {},
   "source": [
    "## == Full Feature Set Used – Performance decreased drastically =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b60683-f3e2-495e-89b9-a350c3091ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use all available features except the label column\n",
    "#model_full_features = df.columns.drop(\"labels\")\n",
    "#X_train_full = df[model_full_features]\n",
    "#y_train_full = df[\"labels\"]\n",
    "\n",
    "## Train Random Forest on full feature set\n",
    "#model_full = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "#model_full.fit(X_train_full, y_train_full)\n",
    "\n",
    "#print(\"Full-feature model trained on\", len(model_full_features), \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6355b8-340e-481e-9921-bd4e5b237c67",
   "metadata": {},
   "source": [
    "# === Test .eml-Data on Model (top features) ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ba3b9-b596-4eda-ad2b-c77115e87eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select same features as used during full-model training\n",
    "X_eml_top_features = df_eml[top_features]\n",
    "\n",
    "# Predict phishing likelihood\n",
    "y_pred_eml_top_features = model_reduced.predict(X_eml_top_features)\n",
    "\n",
    "df_eml[\"Predicted\"] = y_pred_eml_top_features\n",
    "\n",
    "print(classification_report(df_eml[\"CLASS_LABEL\"], df_eml[\"Predicted\"]))\n",
    "print(confusion_matrix(df_eml[\"CLASS_LABEL\"], df_eml[\"Predicted\"]))\n",
    "\n",
    "false_positives = df_eml[(df_eml[\"CLASS_LABEL\"] == 0) & (df_eml[\"Predicted\"] == 1)]\n",
    "false_negatives = df_eml[(df_eml[\"CLASS_LABEL\"] == 1) & (df_eml[\"Predicted\"] == 0)]\n",
    "\n",
    "display(false_positives[[\"FILENAME\", \"Predicted\"]])\n",
    "display(false_negatives[[\"FILENAME\", \"Predicted\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453cb5d7-2e5c-45f0-94a6-b8bb53507047",
   "metadata": {},
   "source": [
    "## == Analysis of Unexpected Model Behavior =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3709bccf-dcd2-429e-9570-b5b371ea6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eml.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e61ac-7fc4-48c9-bab5-52737601e4ac",
   "metadata": {},
   "source": [
    "## == Comparison of false-positives with the distribution of legitimate training data =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe94878-aaa8-4a1a-a962-270162bbc886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only legitimate samples from training data (used for reference distribution)\n",
    "X_legit = X_train[y_train == 0][top_features]\n",
    "\n",
    "# mean and standard deviation for each feature (based on legit emails)\n",
    "mean_legit = X_legit.mean()\n",
    "std_legit = X_legit.std()\n",
    "\n",
    "# Extract false positives\n",
    "false_positives = df_eml[(df_eml[\"CLASS_LABEL\"] == 0) & (df_eml[\"Predicted\"] == 1)]\n",
    "\n",
    "for _, row in false_positives.iterrows():\n",
    "    print(f\"False-Positive: {row['FILENAME']}\")\n",
    "    print(\"## Feature (value) - Z-score vs legit mean ##\\n\")\n",
    "\n",
    "    for feat in top_features:\n",
    "        value = row[feat]\n",
    "        mean = mean_legit[feat]\n",
    "        std = std_legit[feat]\n",
    "        z = (value - mean) / std if std > 0 else 0\n",
    "        print(f\"{feat}: {value:.2f} (z = {z:.2f})\")\n",
    "\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a4b95-269e-4976-beee-6f4b189fd1c1",
   "metadata": {},
   "source": [
    "# === Integrating .eml-Data into the training set ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119ec0b-68bf-40e8-b229-e1143f59d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_mails = process_eml_folder(\"../data/mails/real_mails_train\")\n",
    "\n",
    "# Load original CSV-based dataset and drop unused columns\n",
    "df_csv_base = pd.read_csv(\"../data/Phishing_Legitimate_full.csv\")\n",
    "df_csv_base = df_csv_base.drop(columns=[\"id\", \"HttpsInHostname\"])\n",
    "\n",
    "# Ensure matching columns\n",
    "df_real_mails = df_real_mails[df_csv_base.columns]\n",
    "df_combined = pd.concat([df_csv_base, df_real_mails], ignore_index=True)\n",
    "\n",
    "# Final training dataset\n",
    "df = df_combined\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49fe290-addd-42b0-adc4-f292eb0e747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = df_csv_base.describe().T\n",
    "display(desc)\n",
    "\n",
    "# More Details of original - count of uniques, range of values \n",
    "for col in df_csv_base.columns:\n",
    "    print(f\"{col}: unique={df_csv_base[col].nunique()}, min={df_csv_base[col].min()}, max={df_csv_base[col].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c35b583-f285-4f56-9d42-90df4621ef0a",
   "metadata": {},
   "source": [
    "# === Training on combined dataset ==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ed2ad-da36-4db0-9c7f-cc07921a5cc9",
   "metadata": {},
   "source": [
    "# === CSV + full EML-Train-Data (20 legit, 20 phish) Training ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db4acb3-da8f-4a53-a626-b9a8c5fa1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(\"../data/Phishing_Legitimate_full.csv\")\n",
    "df_csv = df_csv.drop(columns=[\"id\", \"HttpsInHostname\"])\n",
    "\n",
    "df_real_train = process_eml_folder(\"../data/mails/real_mails_train\")\n",
    "\n",
    "# Assure same features\n",
    "df_real_train = df_real_train[df_csv.columns]\n",
    "\n",
    "df_train_full_combined  = pd.concat([df_csv, df_real_train], ignore_index=True)\n",
    "\n",
    "# Full Feature Training\n",
    "X_train_full_combined = df_train_full_combined.drop(columns=[\"CLASS_LABEL\"])\n",
    "y_train_full_combined = df_train_full_combined[\"CLASS_LABEL\"]\n",
    "\n",
    "model_full_combined_csv_eml = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_full_combined_csv_eml.fit(X_train_full_combined, y_train_full_combined)\n",
    "\n",
    "# Reduced Feature Training\n",
    "# Use the same top_features as in earlier analysis (from feature_importance[:15].index)\n",
    "X_train_top_combined = df_train_full_combined[top_features]\n",
    "\n",
    "model_top_combined_csv_eml = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_top_combined_csv_eml.fit(X_train_top_combined, y_train_full_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04daf6f-136a-4b65-86fe-1a8a9449296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_real = process_eml_folder(\"../data/mails/real_mails_test\")\n",
    "\n",
    "# Full feature input\n",
    "X_test_full = df_test_real[X_train_full_combined.columns]\n",
    "\n",
    "# Reduced feature input\n",
    "X_test_top = df_test_real[top_features]\n",
    "y_test = df_test_real[\"CLASS_LABEL\"]\n",
    "\n",
    "# Predictions\n",
    "y_pred_full = model_full_combined_csv_eml.predict(X_test_full)\n",
    "y_pred_top = model_top_combined_csv_eml.predict(X_test_top)\n",
    "\n",
    "df_test_real[\"Predicted_Full\"] = y_pred_full\n",
    "df_test_real[\"Predicted_Top\"] = y_pred_top\n",
    "\n",
    "# Evaluation: Full model\n",
    "print(\"Evaluation on Real EML Test Data (Full Feature Model)\")\n",
    "print(classification_report(y_test, y_pred_full))\n",
    "print(confusion_matrix(y_test, y_pred_full))\n",
    "\n",
    "false_pos_full = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 0) & (df_test_real[\"Predicted_Full\"] == 1)]\n",
    "false_neg_full = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 1) & (df_test_real[\"Predicted_Full\"] == 0)]\n",
    "\n",
    "print(\"\\nFalse Positives (Full Feature Model)\")\n",
    "display(false_pos_full[[\"FILENAME\", \"Predicted_Full\"]])\n",
    "\n",
    "print(\"\\nFalse Negatives (Full Feature Model)\")\n",
    "display(false_neg_full[[\"FILENAME\", \"Predicted_Full\"]])\n",
    "\n",
    "# Evaluation: Top feature model\n",
    "print(\"\\nEvaluation on Real EML Test Data (Top Feature Model)\")\n",
    "print(classification_report(y_test, y_pred_top))\n",
    "print(confusion_matrix(y_test, y_pred_top))\n",
    "\n",
    "false_pos_top = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 0) & (df_test_real[\"Predicted_Top\"] == 1)]\n",
    "false_neg_top = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 1) & (df_test_real[\"Predicted_Top\"] == 0)]\n",
    "\n",
    "print(\"\\nFalse Positives (Top Feature Model)\")\n",
    "display(false_pos_top[[\"FILENAME\", \"Predicted_Top\"]])\n",
    "\n",
    "print(\"\\nFalse Negatives (Top Feature Model)\")\n",
    "display(false_neg_top[[\"FILENAME\", \"Predicted_Top\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6563f-f4a0-40db-9137-0985da4ebe74",
   "metadata": {},
   "source": [
    "# === CSV + full EML-Train-Data (20 legit, 20 phish) XGB Training ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713dc88e-f610-4b27-9c66-9cdab8f990c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(\"../data/Phishing_Legitimate_full.csv\")\n",
    "df_csv = df_csv.drop(columns=[\"id\", \"HttpsInHostname\"])\n",
    "\n",
    "df_real_train = process_eml_folder(\"../data/mails/real_mails_train\")\n",
    "df_real_train = df_real_train[df_csv.columns]\n",
    "\n",
    "df_train_combined = pd.concat([df_csv, df_real_train], ignore_index=True)\n",
    "\n",
    "# XGBoost - Full Feature Model\n",
    "X_train_full_combined = df_train_combined.drop(columns=[\"CLASS_LABEL\"])\n",
    "y_train_full_combined = df_train_combined[\"CLASS_LABEL\"]\n",
    "\n",
    "model_xgb_combined_csv_eml = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=77\n",
    ")\n",
    "model_xgb_combined_csv_eml.fit(X_train_full_combined, y_train_full_combined)\n",
    "\n",
    "# XGBoost - Top Feature Model\n",
    "X_train_top_combined = df_train_combined[top_features]\n",
    "\n",
    "model_xgb_top_combined_csv_eml = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=77\n",
    ")\n",
    "model_xgb_top_combined_csv_eml.fit(X_train_top_combined, y_train_full_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c518e-cd0c-4d78-8843-61a321941cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_real = process_eml_folder(\"../data/mails/real_mails_test\")\n",
    "\n",
    "X_test_full = df_test_real[X_train_full_combined.columns]\n",
    "X_test_top = df_test_real[top_features]\n",
    "y_test = df_test_real[\"CLASS_LABEL\"]\n",
    "\n",
    "y_pred_full = model_xgb_combined_csv_eml.predict(X_test_full)\n",
    "y_pred_top = model_xgb_top_combined_csv_eml.predict(X_test_top)\n",
    "\n",
    "df_test_real[\"Predicted_Full_XGB\"] = y_pred_full\n",
    "df_test_real[\"Predicted_Top_XGB\"] = y_pred_top\n",
    "\n",
    "# Evaluation: Full Feature Model\n",
    "print(\"Evaluation (XGBoost Full Feature Model)\")\n",
    "print(classification_report(y_test, y_pred_full))\n",
    "print(confusion_matrix(y_test, y_pred_full))\n",
    "\n",
    "# Evaluation: Top Feature Model\n",
    "print(\"\\nEvaluation (XGBoost Top Feature Model)\")\n",
    "print(classification_report(y_test, y_pred_top))\n",
    "print(confusion_matrix(y_test, y_pred_top))\n",
    "\n",
    "# False Positives / Negatives - Full Feature\n",
    "fp_full = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 0) & (df_test_real[\"Predicted_Full_XGB\"] == 1)]\n",
    "fn_full = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 1) & (df_test_real[\"Predicted_Full_XGB\"] == 0)]\n",
    "\n",
    "print(\"\\nFalse Positives (Full Feature)\")\n",
    "display(fp_full[[\"FILENAME\", \"Predicted_Full_XGB\"]])\n",
    "\n",
    "print(\"\\nFalse Negatives (Full Feature)\")\n",
    "display(fn_full[[\"FILENAME\", \"Predicted_Full_XGB\"]])\n",
    "\n",
    "# False Positives / Negatives - Top Feature\n",
    "fp_top = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 0) & (df_test_real[\"Predicted_Top_XGB\"] == 1)]\n",
    "fn_top = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 1) & (df_test_real[\"Predicted_Top_XGB\"] == 0)]\n",
    "\n",
    "print(\"\\nFalse Positives (Top Feature)\")\n",
    "display(fp_top[[\"FILENAME\", \"Predicted_Top_XGB\"]])\n",
    "\n",
    "print(\"\\nFalse Negatives (Top Feature)\")\n",
    "display(fn_top[[\"FILENAME\", \"Predicted_Top_XGB\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42fa0a4-40fb-4f66-ae2b-313d625530ce",
   "metadata": {},
   "source": [
    "# === Train only on EML training data ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467b132-40ea-43d6-b004-55309887545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_real = process_eml_folder(\"../data/mails/real_mails_train\")\n",
    "\n",
    "# Full Feature Model\n",
    "X_train_real_full = df_train_real.drop(columns=[\"CLASS_LABEL\", \"FILENAME\"])\n",
    "y_train_real = df_train_real[\"CLASS_LABEL\"]\n",
    "\n",
    "model_real_full = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_real_full.fit(X_train_real_full, y_train_real)\n",
    "\n",
    "# Top Feature Model\n",
    "X_train_real_top = df_train_real[top_features]\n",
    "\n",
    "model_real_top = RandomForestClassifier(n_estimators=100, random_state=77)\n",
    "model_real_top.fit(X_train_real_top, y_train_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87197e8-a4ae-4e06-b7e3-12a6a4f92c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_real = process_eml_folder(\"../data/mails/real_mails_test\")\n",
    "\n",
    "X_test_real_full = df_test_real[X_train_real_full.columns]\n",
    "X_test_real_top = df_test_real[top_features]\n",
    "y_test_real = df_test_real[\"CLASS_LABEL\"]\n",
    "\n",
    "# Predictions\n",
    "y_pred_real_full = model_real_full.predict(X_test_real_full)\n",
    "y_pred_real_top = model_real_top.predict(X_test_real_top)\n",
    "\n",
    "df_test_real[\"Predicted_Full\"] = y_pred_real_full\n",
    "df_test_real[\"Predicted_Top\"] = y_pred_real_top\n",
    "\n",
    "# Evaluation Full Feature Model\n",
    "print(\"Evaluation (Full Feature Model trained on real_mails_train only)\")\n",
    "print(classification_report(y_test_real, y_pred_real_full))\n",
    "print(confusion_matrix(y_test_real, y_pred_real_full))\n",
    "\n",
    "# Evaluation Top Feature Model\n",
    "print(\"\\nEvaluation (Top Feature Model trained on real_mails_train only)\")\n",
    "print(classification_report(y_test_real, y_pred_real_top))\n",
    "print(confusion_matrix(y_test_real, y_pred_real_top))\n",
    "\n",
    "# False Positives / Negatives: Full Model\n",
    "fp_real_full = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 0) & (df_test_real[\"Predicted_Full\"] == 1)]\n",
    "fn_real_full = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 1) & (df_test_real[\"Predicted_Full\"] == 0)]\n",
    "\n",
    "print(\"\\nFalse Positives (Full Model)\")\n",
    "display(fp_real_full[[\"FILENAME\", \"Predicted_Full\"]])\n",
    "\n",
    "print(\"\\nFalse Negatives (Full Model)\")\n",
    "display(fn_real_full[[\"FILENAME\", \"Predicted_Full\"]])\n",
    "\n",
    "# False Positives / Negatives: Top Feature Model\n",
    "fp_real_top = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 0) & (df_test_real[\"Predicted_Top\"] == 1)]\n",
    "fn_real_top = df_test_real[(df_test_real[\"CLASS_LABEL\"] == 1) & (df_test_real[\"Predicted_Top\"] == 0)]\n",
    "\n",
    "print(\"\\nFalse Positives (Top Feature Model)\")\n",
    "display(fp_real_top[[\"FILENAME\", \"Predicted_Top\"]])\n",
    "\n",
    "print(\"\\nFalse Negatives (Top Feature Model)\")\n",
    "display(fn_real_top[[\"FILENAME\", \"Predicted_Top\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4ea15-606f-4af3-807b-46963fda49a3",
   "metadata": {},
   "source": [
    "# === Train only on EML training data XGB ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe2901c-e903-4072-bb7e-994608f903a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_real = process_eml_folder(\"../data/mails/real_mails_train\")\n",
    "\n",
    "# Full features\n",
    "X_train_real_full = df_train_real.drop(columns=[\"CLASS_LABEL\", \"FILENAME\"])\n",
    "y_train_real = df_train_real[\"CLASS_LABEL\"]\n",
    "\n",
    "model_real_full_xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=77\n",
    ")\n",
    "model_real_full_xgb.fit(X_train_real_full, y_train_real)\n",
    "\n",
    "# Top features\n",
    "X_train_real_top = df_train_real[top_features]\n",
    "\n",
    "model_real_top_xgb = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=77\n",
    ")\n",
    "model_real_top_xgb.fit(X_train_real_top, y_train_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd58c41-da6b-4e1f-b1ab-a46abe29fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_real = process_eml_folder(\"../data/mails/real_mails_test\")\n",
    "y_test_real = df_test_real[\"CLASS_LABEL\"]\n",
    "\n",
    "X_test_real_full = df_test_real[X_train_real_full.columns]\n",
    "X_test_real_top = df_test_real[top_features]\n",
    "\n",
    "y_pred_real_full = model_real_full_xgb.predict(X_test_real_full)\n",
    "y_pred_real_top = model_real_top_xgb.predict(X_test_real_top)\n",
    "\n",
    "df_test_real[\"Predicted_Full_XGB\"] = y_pred_real_full\n",
    "df_test_real[\"Predicted_Top_XGB\"] = y_pred_real_top\n",
    "\n",
    "# Evaluation Full Feature Model\n",
    "print(\"Evaluation (XGBoost Full Feature Model)\")\n",
    "print(classification_report(y_test_real, y_pred_real_full))\n",
    "print(confusion_matrix(y_test_real, y_pred_real_full))\n",
    "\n",
    "# Evaluation Top Feature Model\n",
    "print(\"\\nEvaluation (XGBoost Top Feature Model)\")\n",
    "print(classification_report(y_test_real, y_pred_real_top))\n",
    "print(confusion_matrix(y_test_real, y_pred_real_top))\n",
    "\n",
    "# False Positives / Negatives: Full Feature\n",
    "fp_full = df_test_real[(y_test_real == 0) & (df_test_real[\"Predicted_Full_XGB\"] == 1)]\n",
    "fn_full = df_test_real[(y_test_real == 1) & (df_test_real[\"Predicted_Full_XGB\"] == 0)]\n",
    "\n",
    "print(\"\\nFalse Positives (Full Model)\")\n",
    "display(fp_full[[\"FILENAME\", \"Predicted_Full_XGB\"]])\n",
    "\n",
    "print(\"\\nFalse Negatives (Full Model)\")\n",
    "display(fn_full[[\"FILENAME\", \"Predicted_Full_XGB\"]])\n",
    "\n",
    "# False Positives / Negatives: Top Feature\n",
    "fp_top = df_test_real[(y_test_real == 0) & (df_test_real[\"Predicted_Top_XGB\"] == 1)]\n",
    "fn_top = df_test_real[(y_test_real == 1) & (df_test_real[\"Predicted_Top_XGB\"] == 0)]\n",
    "\n",
    "print(\"\\nFalse Positives (Top Model)\")\n",
    "display(fp_top[[\"FILENAME\", \"Predicted_Top_XGB\"]])\n",
    "\n",
    "print(\"\\nFalse Negatives (Top Model)\")\n",
    "display(fn_top[[\"FILENAME\", \"Predicted_Top_XGB\"]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
